{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 2rem;\">Take `classify_classifications.csv` and parse into various dataframes for analysis. Do this here to keep the length of our analysis notebooks manageable.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from dateutil.parser import parse\n",
    "from datetime import date\n",
    "\n",
    "import sys \n",
    "sys.path.append('..')\n",
    "from sf import getFilename, parseTime, extract_task_value, percentageVotesForAnswer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Parse the dataframe itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract unique object names that resulted from another notebook \n",
    "candidate_names_classify = np.loadtxt('../sf_objectImageStrings__classification-classify.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe\n",
    "df = pd.read_csv('../../SpaceFluff/zooniverse_exports/classify-classifications.csv', delimiter=\",\")\n",
    "\n",
    "# JSON parse the columns that were stringified\n",
    "columns_to_parse = ['annotations', 'subject_data', 'metadata']\n",
    "\n",
    "for column in columns_to_parse:\n",
    "    df[column] = df[column].apply(json.loads)\n",
    "    \n",
    "# extract filename, task0 and task1 values to new dataframe columns\n",
    "df['Filename'] = df['subject_data'].apply(getFilename)\n",
    "df['Task0'] = df['annotations'].apply(lambda x: extract_task_value(0, x))\n",
    "df['Task1'] = df['annotations'].apply(lambda x: extract_task_value(1, x))\n",
    "\n",
    "# finally, remove all rows where task0 wasn't answered (because the row, then, is useless)\n",
    "df = df[~df['Task0'].isnull()]\n",
    "\n",
    "# filter out classifications from beta\n",
    "df['created_at'] = df['created_at'].apply(parseTime)\n",
    "end_of_beta = pd.Timestamp(date(2020,10,20), tz='utc')\n",
    "df = df[df['created_at'] > end_of_beta]\n",
    "\n",
    "# create temporary isRetired and alreadySeen rows\n",
    "df['isRetired'] = df['metadata'].apply(lambda x: x['subject_selection_state']['retired'])\n",
    "df['alreadySeen'] = df['metadata'].apply(lambda x: x['subject_selection_state']['already_seen'])\n",
    "\n",
    "# remove rows where isRetired or alreadySeen\n",
    "df = df[~df['isRetired'] & ~df['alreadySeen']]\n",
    "\n",
    "# remove isRetired and alreadySeen columns since they're obsolete hereafter\n",
    "df.drop(['isRetired', 'alreadySeen'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_name': 1783, 'user_ip': 1157, 'user_id': 1136}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.user_name.isnull()]  # returns empty df, so every classification has a user_name associated with it\n",
    "df[df.user_ip.isnull()]  # also returns empty df\n",
    "\n",
    "unique_entries = {\n",
    "    \"user_name\": df.user_name.unique().shape[0],\n",
    "    \"user_ip\": df.user_ip.unique().shape[0],\n",
    "    \"user_id\": df.user_id.unique().shape[0]\n",
    "}\n",
    "\n",
    "unique_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the above shows that there's more unique usernames than either ips or ids. Assume multiple people may share an IP, and note that not all classifications have an associated user_id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Create 'task0' dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group df by filename, so that each group contains only rows belonging to that object\n",
    "gr = df.groupby('Filename')\n",
    "\n",
    "# create empty list to push results to\n",
    "task0Values = []\n",
    "\n",
    "# loop over every group created above to accumulate 'task 0' votes ('galaxy'/'group of objects'/'something else')\n",
    "for objectName in candidate_names_classify:\n",
    "    try:\n",
    "        task0 = gr.get_group(objectName)['Task0']\n",
    "\n",
    "        counts = task0.value_counts().to_dict()\n",
    "\n",
    "        countObj = {\n",
    "            \"name\": objectName,\n",
    "            \"counts\": counts,\n",
    "        }\n",
    "\n",
    "        task0Values.append(countObj)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "df_task0 = pd.DataFrame(task0Values)\n",
    "\n",
    "answer_types = ['Galaxy', 'Group of objects (Cluster)', 'Something else/empty center']\n",
    "\n",
    "df_task0['# votes'] = df_task0['counts'].apply(lambda x: sum(x.values()))\n",
    "\n",
    "for ans_type in answer_types:\n",
    "    vote_percentage_column = df_task0['counts'].apply(lambda x: percentageVotesForAnswer(x, ans_type))\n",
    "    df_task0['% votes {}'.format(ans_type)] = vote_percentage_column\n",
    "    \n",
    "df_task0['name'] = df_task0['name'].apply(lambda x: x[:-9])\n",
    "\n",
    "# filter dataframe and only leave objects with more than 5 votes\n",
    "df_task0 = df_task0[df_task0['# votes'] > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Create 'df_retired' and 'df_with_props' dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_retired_info(subject_data):\n",
    "    '''\n",
    "        @param subject_data: (dataframe 'subject_data' column)\n",
    "    '''\n",
    "    return list(subject_data.values())[0][\"retired\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"retired\"] = df[\"subject_data\"].apply(extract_retired_info)\n",
    "df_retired = df[~df[\"retired\"].isnull()]\n",
    "\n",
    "gr_retired = df_retired.groupby([\"Filename\"])  # group by filename\n",
    "props = [\"R\", \"RA\", \"DEC\", \"G-I\"]              # extract object properties\n",
    "\n",
    "props_list = []\n",
    "\n",
    "for objectName in candidate_names_classify:\n",
    "    # get group\n",
    "    try:\n",
    "        row = gr_retired.get_group(objectName)['subject_data']\n",
    "\n",
    "        # get first entry in the group (props should be the same for every entry since they all describe the same object)\n",
    "        firstEntry = row.iloc[0]\n",
    "        values  = list(firstEntry.values())[0]\n",
    "\n",
    "        # create object with name, properties\n",
    "        entry = {'name': objectName[:-9]}\n",
    "\n",
    "        for key in props:\n",
    "            entry[key] = values[key]\n",
    "\n",
    "        props_list.append(entry)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "df_props = pd.DataFrame(props_list)\n",
    "\n",
    "df_with_props = df_task0.merge(df_props, how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ## Create 'task1' dataframe, and merge it with 'task0' dataframe to get 'tasks' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a temporary dataframe containing only classifications where 'task0' == 'Galaxy'\n",
    "# df_galaxy = df[(df['Task0'] == 'Galaxy') & (df['annotations'].map(len) > 1)]\n",
    "df_galaxy = df[(df['Task0'] == 'Galaxy')]\n",
    "galaxy_names = df_galaxy['Filename']\n",
    "\n",
    "gr_by_name = df.groupby(['Filename'])\n",
    "\n",
    "galaxy_task1_values = []\n",
    "\n",
    "for name in set(galaxy_names):\n",
    "    group = gr_by_name.get_group(name)        # get all classifications of this object from df\n",
    "    group = group[group['Task0'] == 'Galaxy'] # select only rows where task0 was answered with 'galaxy'\n",
    "    \n",
    "    rowObj = {}\n",
    "    \n",
    "    # add 'fluffy' and 'bright' rows\n",
    "    for answer in ['Fluffy', 'Bright']:\n",
    "        rowObj['% {}'.format(answer)] = round(list(group['Task1']).count(answer)*100/group.shape[0], 1)\n",
    "    \n",
    "    # also manually add 'None' row since None is parsed to NaN otherwise\n",
    "    none_count = group[group['Task1'].isnull()].shape[0]\n",
    "    rowObj['% None'] = round(none_count*100/group.shape[0], 1)\n",
    "    rowObj['name'] = name[:-9]  # add object's name to rowObj\n",
    "    \n",
    "    galaxy_task1_values.append(rowObj)  # append rowObj to list\n",
    "\n",
    "df_task1 = pd.DataFrame(galaxy_task1_values)\n",
    "\n",
    "df_tasks = df_task1.merge(df_task0, on='name', how='outer')\n",
    "\n",
    "object_info = pd.read_csv('../../catalogue/sf_spacefluff_object_data.csv', comment=\"#\")\n",
    "\n",
    "# merge properties onto dataframe\n",
    "df_tasks_with_props = df_tasks.merge(object_info, how='outer', on='name')\n",
    "\n",
    "# filter out objects without actual votes\n",
    "df_tasks_with_props = df_tasks_with_props[~df_tasks_with_props['# votes'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tasks[~df_tasks['% None'].isnull() & df_tasks['% None'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the end, we end up with the following dataframes:\n",
    "- `df`: \n",
    "        parsed version of the complete data set\n",
    "        \n",
    "- `df_galaxy`: \n",
    "        filtered version of `df` leaving classifications where task0 == 'galaxy'\n",
    "        \n",
    "- `df_retired`, `df_props`: \n",
    "        temporary dataframes, both used to create `df_with_props`\n",
    "        \n",
    "- `df_task0`:\n",
    "        Contains the name of each galaxy, the total number of votes, and the percentage of votes for each option from task0.\n",
    "        \n",
    "- `df_with_props`:\n",
    "        version of df_task0 with the properties of each galaxy merged onto it\n",
    "        \n",
    "- `df_task1`:\n",
    "        contains the name of each galaxy, and the percentage of votes for 'fluffy' and 'bright' for task1, asked as a follow-up when people answered 'Galaxy' for task0.\n",
    "        \n",
    "- `df_tasks`:\n",
    "        df_task1 outer joined onto df_task0\n",
    "        \n",
    "- `df_tasks_with_props`:\n",
    "        df_tasks merged with object info (from Venhola's catalogue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### Export df_tasks_with_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tasks_with_props.to_csv('./tasks_with_props.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./df.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
