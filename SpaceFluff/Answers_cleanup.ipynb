{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Zooniverse Data Exports for Space Fluff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global exports_dir\n",
    "global outputs_dir\n",
    "#exports_dir = /home/anna/Desktop/SUNDIAL/images/\n",
    "#outputs_dir = /home/anna/Desktop/SUNDIAL/images/\n",
    "exports_dir = 'zooniverse_exports/'\n",
    "outputs_dir = 'outputs'\n",
    "\n",
    "filename_classify = exports_dir+'classify-classifications.csv'\n",
    "filename_onthego = exports_dir+'classify-on-the-go-classifications.csv'\n",
    "filename_hardcore = exports_dir+'classify-hardcore-edition-classifications.csv'\n",
    "\n",
    "outputfile_classify = exports_dir+'space-fluff_classifications_clean.csv'\n",
    "outputfile_onthego = exports_dir+'space-fluff_onthego_clean.csv'\n",
    "outputfile_hardcore = exports_dir+'space-fluff_hardcore_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_out_classify = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_T0_classify', 'taskvalue_T1_classify', 'taskvalue_T2_classify',\n",
    "                'subject_name_classify']\n",
    "columns_out_onthego = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_T0_onthego', 'subject_name_onthego']\n",
    "\n",
    "# not all tasks are active in the hardcore workflow: amt there is T0, T2, T1, T3, T4, T5, T9 \n",
    "\n",
    "columns_out_hardcore = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_T0', 'taskvalue_T1','taskvalue_T2', 'taskvalue_T3',\n",
    "                'taskvalue_T4', 'taskvalue_T5', 'taskvalue_T9', 'subject_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_in = ['classification_id', 'user_name', 'user_id', 'user_ip', \n",
    "              'workflow_id','workflow_name', 'workflow_version', 'created_at', \n",
    "              'gold_standard', 'expert', 'metadata', 'annotations', \n",
    "              'subject_data', 'subject_ids']\n",
    "       \n",
    "columns_new_classify = ['metadata_json_classify', 'annotations_json_classify',\n",
    "                'subject_data_json_classify', \n",
    "               'taskvalue_T0_classify', 'taskvalue_T1_classify', 'taskvalue_T2_classify',\n",
    "                'subject_name_classify']\n",
    "columns_new_onthego = ['metadata_json_onthego', 'annotations_json_onthego',\n",
    "                'subject_data_json_onthego', \n",
    "               'taskvalue_T0_onthego', 'subject_name_onthego']\n",
    "columns_new_hardcore = ['metadata_json', 'annotations_json', 'subject_data_json', \n",
    "               'taskvalue_T0', 'taskvalue_T1','taskvalue_T2', 'taskvalue_T3',\n",
    "                'taskvalue_T4', 'taskvalue_T5', 'taskvalue_T9', 'subject_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_classify = pd.read_csv(filename_classify)\n",
    "classifications_classify = classifications_classify[6295:]\n",
    "\n",
    "classifications_onthego = pd.read_csv(filename_onthego)\n",
    "classifications_onthego = classifications_onthego[19989:]\n",
    "\n",
    "classifications_hardcore = pd.read_csv(filename_hardcore)\n",
    "classifications_hardcore = classifications_hardcore[5945:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_classify['metadata_json'] = [json.loads(q) for q in classifications_classify.metadata]\n",
    "classifications_classify['annotations_json'] = [json.loads(q) for q in classifications_classify.annotations]\n",
    "classifications_classify['subject_data_json'] = [json.loads(q) for q in classifications_classify.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_onthego['metadata_json'] = [json.loads(q) for q in classifications_onthego.metadata]\n",
    "classifications_onthego['annotations_json'] = [json.loads(q) for q in classifications_onthego.annotations]\n",
    "classifications_onthego['subject_data_json'] = [json.loads(q) for q in classifications_onthego.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_hardcore['metadata_json'] = [json.loads(q) for q in classifications_hardcore.metadata]\n",
    "classifications_hardcore['annotations_json'] = [json.loads(q) for q in classifications_hardcore.annotations]\n",
    "classifications_hardcore['subject_data_json'] = [json.loads(q) for q in classifications_hardcore.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions to make things a bit cleaner\n",
    "\n",
    "def clean_answers_onthego(classifications, annotations_columns): \n",
    "    for i, row in classifications.iterrows():\n",
    "        answers = {'T0':''}\n",
    "        for t in row[annotations_columns]:\n",
    "            answers[t['task']] = t['value']\n",
    "        taskvalue_T0_onthego.append(answers['T0'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def clean_answers_classify(classifications, annotations_columns): \n",
    "    for i, row in classifications.iterrows():\n",
    "        answers = {'T0':'', 'T1':'', 'T2':''}\n",
    "        for t in row[annotations_columns]:\n",
    "            answers[t['task']] = t['value']\n",
    "        taskvalue_T0_classify.append(answers['T0'])\n",
    "        taskvalue_T1_classify.append(answers['T1'])\n",
    "        taskvalue_T2_classify.append(answers['T2'])\n",
    "\n",
    "    \n",
    "\n",
    "def clean_answers_hardcore(classifications, annotations_columns): \n",
    "    for i, row in classifications.iterrows():\n",
    "        answers = {'T0':'', 'T1':'', 'T2':'', 'T3':'', 'T4':'', 'T5':'', 'T9':''}\n",
    "        for t in row[annotations_columns]:\n",
    "            #print(t['task'],',  ',t['value'])\n",
    "            answers[t['task']] = t['value']\n",
    "        #print(answered)\n",
    "        taskvalue_T0.append(answers['T0'])\n",
    "        taskvalue_T1.append(answers['T1'])\n",
    "        taskvalue_T2.append(answers['T2'])\n",
    "        taskvalue_T3.append(answers['T3'])\n",
    "        taskvalue_T4.append(answers['T4'])\n",
    "        taskvalue_T5.append(answers['T5'])\n",
    "        taskvalue_T9.append(answers['T9'])\n",
    "         \n",
    "        #print('len of taskvalue: ', len(taskvalue_T0))\n",
    "\n",
    "def add_subject_name(classifications):\n",
    "    subject_name = []\n",
    "    for row in classifications['subject_data']:\n",
    "        image_no = row.split('IMAGE\":\"')[1]\n",
    "        subject_name.append(image_no.split('\"')[0])\n",
    "    #print('len of subj:  ',len(subject_name))    \n",
    "    return subject_name\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-bbe87c1912d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mclean_answers_hardcore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifications_hardcore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'annotations_json'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0msubject_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madd_subject_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifications_hardcore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mclassifications_hardcore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'taskvalue_T0'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtaskvalue_T0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-494e560b23cc>\u001b[0m in \u001b[0;36madd_subject_name\u001b[1;34m(classifications)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0msubject_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclassifications\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'subject_data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mimage_no\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'IMAGE\":\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[0msubject_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;31m#print('len of subj:  ',len(subject_name))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "taskvalue_T0 = []\n",
    "taskvalue_T1 = []\n",
    "taskvalue_T2 = []\n",
    "taskvalue_T3 = []\n",
    "taskvalue_T4 = []\n",
    "taskvalue_T5 = []\n",
    "taskvalue_T9 = []\n",
    "\n",
    "\n",
    "clean_answers_hardcore(classifications_hardcore, 'annotations_json')\n",
    "subject_names = add_subject_name(classifications_hardcore)\n",
    "\n",
    "classifications_hardcore['taskvalue_T0'] = taskvalue_T0\n",
    "classifications_hardcore['taskvalue_T1'] = taskvalue_T1\n",
    "classifications_hardcore['taskvalue_T2'] = taskvalue_T2\n",
    "classifications_hardcore['taskvalue_T3'] = taskvalue_T3\n",
    "classifications_hardcore['taskvalue_T4'] = taskvalue_T4\n",
    "classifications_hardcore['taskvalue_T5'] = taskvalue_T5\n",
    "classifications_hardcore['taskvalue_T9'] = taskvalue_T9\n",
    "classifications_hardcore['subject_name'] = subject_names\n",
    "\n",
    "print(classifications_hardcore['taskvalue_T0'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskvalue_T0_onthego = []\n",
    "\n",
    "clean_answers_onthego(classifications_onthego, 'annotations_json')\n",
    "subject_names_onthego = add_subject_name(classifications_onthego)\n",
    "\n",
    "classifications_onthego['taskvalue_T0_onthego'] = taskvalue_T0_onthego\n",
    "classifications_onthego['subject_name_onthego'] = subject_names_onthego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskvalue_T0_classify = []\n",
    "taskvalue_T1_classify = []\n",
    "taskvalue_T2_classify = []\n",
    "\n",
    "clean_answers_classify(classifications_classify, 'annotations_json')\n",
    "subject_names_classify = add_subject_name(classifications_classify)\n",
    "\n",
    "\n",
    "classifications_classify['taskvalue_T0_classify'] = taskvalue_T0_classify\n",
    "classifications_classify['taskvalue_T1_classify'] = taskvalue_T1_classify\n",
    "classifications_classify['taskvalue_T2_classify'] = taskvalue_T2_classify\n",
    "classifications_classify['subject_name_classify'] = subject_names_classify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hardcore = classifications_hardcore[columns_out_hardcore]\n",
    "output_hardcore.to_csv(outputfile_hardcore, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classify = classifications_classify[columns_out_classify]\n",
    "output_classify.to_csv(outputfile_classify, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_onthego = classifications_onthego[columns_out_onthego]\n",
    "output_onthego.to_csv(outputfile_onthego, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
