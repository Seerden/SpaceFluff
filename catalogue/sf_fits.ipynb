{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info\n",
    "We are able to use two catalogues:\n",
    "- `LSBS_no_par_sel` contains a number of objects, including many of the objects used in SpaceFluff.\n",
    "- `FDSDWARF_LSB` contains objects expected to be LSB dwarfs or UDGs in the Fornax cluster, on the basis of their physical properties.\n",
    "\n",
    "### Goal\n",
    "The goal of this notebook is to extract the physical properties (color, surface brightness, effective radius, etc.) of all the objects present in the catalogue, so we can attach them to our SpaceFluff data for analysis. We also want to extract (the names of) the objects thought to be LSB/UDG Fornax cluster members, as a supposed form of 'ground truth' against which to compare the voting behavior of SpaceFluff volunteers.\n",
    "\n",
    "### Findings\n",
    "\n",
    "In this notebook, we'll come to find out that:\n",
    "- the object names (e.g. 'UDGcand_102') from the catalogue(s) match those used in SpaceFluff, so we can use the objects' names as handles to compare. Alternatively, coordinates (RA/DEC) also be used.\n",
    "- the two catalogues mentioned above find the same object properties (color, concentration, effective radius, etc.), so it doesn't matter from which of the two we extract the properties. There are a few parameters present in each of the catalogues that aren't in the other, and sometimes the names differ (e.g. `PA` vs `pos_angle`). The only relevant difference for us is the presence of a surface brightness (`mue_r`, $\\mu_{e,r}$) in one catalogue. We need this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract catalogue data\n",
    "\n",
    "## Extract `FDSDWARF_LSB.fits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "FDSDWARF_LSB columns: ['target', 'RA', 'DEC', 'PA', 'PA_e', 'arat', 'arat_e', 'r_mag', 'r_mag_e', 'g_mag', 'g_mag_e', 'r_nuc', 'g_nuc', 'reff', 'reff_e', 'n', 'n_e', 'u', 'u_e', 'g', 'g_e', 'r', 'r_e', 'i', 'i_e', 'C', 'RFF', 'Class', 'Ref.']\n"
     ]
    }
   ],
   "source": [
    "# load fits file, and extract column names and object data\n",
    "\n",
    "hdul = fits.open('./FDSDWARF_LSB.fits')\n",
    "header = hdul[0].header\n",
    "data_selective = hdul[1].data\n",
    "\n",
    "col_names = data_selective.columns.names\n",
    "print('FDSDWARF_LSB columns:', col_names)\n",
    "\n",
    "# extract each target's name to a list. \n",
    "#  these target names match those used in SpaceFluff (we'll verify this later in this notebook)\n",
    "targets_selective = [d['target'] for d in data_selective if 'UDGcand' in d['target']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See http://cdsarc.u-strasbg.fr/ftp/J/A+A/620/A165/ReadMe for description of the columns printed above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over every entry in data_selective (which is the `FDSDWARF_LSB.fits` file) and map its properties to a dictionary.\n",
    "\n",
    "selected_data = []\n",
    "\n",
    "for d in data_selective:\n",
    "    if 'UDGcand' in d['target']:\n",
    "        \n",
    "        object_properties = {\n",
    "            \"name\": d[0]  # first manually assign 'name', since I prefer 'name' to 'target'\n",
    "        }\n",
    "        \n",
    "        for idx, column in enumerate(data_selective.columns.names[1:]):  # then loop over the rest of the properties \n",
    "            object_properties[column] = d[idx+1]                         # and assign the property using its existing name\n",
    "        \n",
    "        \n",
    "        selected_data.append(object_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save target names to txt file for later comparison to classification votes\n",
    "#  we only need to this this once. Can uncomment the cell if we need to run it again.\n",
    "\n",
    "# np.savetxt('sf_catalogue_targets.txt', targets, delimiter=',', fmt=\"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in notebook `sf_12-04-2021`, I extracted a list of unique target names from `classify-classifications.csv`. \n",
    "candidate_names_classify = np.loadtxt('../analysis/sf_candidate_names__classification-classify.txt', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of intersecting targets: 238\n"
     ]
    }
   ],
   "source": [
    "# find intersection of names between FDSDWARF_LSB.fits and classify_classifications.csv\n",
    "intersecting = list(set(targets_selective) & set(candidate_names_classify))\n",
    "\n",
    "print('Number of intersecting targets:', len(intersecting))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract `LSBS_no_par_sel.fits`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LSBS_no_par_sel columns: ['target', 'RA', 'DEC', 'Reff', 'r_mag', 'g_mag', 'axis_ratio', 'pos_angle', 'n', 'u', 'g', 'r', 'i', 'ue', 'ge', 're', 'ie', 'Reffe', 'r_mage', 'ne', 'C', 'mue_r', 'bae', 'RFF']\n"
     ]
    }
   ],
   "source": [
    "hdul = fits.open('./LSBS_no_par_sel.fits')\n",
    "header = hdul[0].header\n",
    "data_no_selection = hdul[1].data\n",
    "\n",
    "# extract all UDGcand_* targets from LSBS_no_par_sel\n",
    "#  note that this fits file also contains other targets. we might want to check if any of those happen to be \n",
    "#   spacefluff candidates, but with another name. check using RA/dec\n",
    "targets_no_selection = [d['target'] for d in data_no_selection if 'UDGcand' in d['target']]\n",
    "\n",
    "print('LSBS_no_par_sel columns:', data_no_selection.columns.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map targets' properties to a list of objects, same as above with FDS_DWARF_LSB\n",
    "\n",
    "spacefluff_data = []\n",
    "\n",
    "for d in data_no_selection:\n",
    "    if d['target'] in set(candidate_names_classify):\n",
    "        \n",
    "        object_properties = {\n",
    "            \"name\": d[0]\n",
    "        }\n",
    "        \n",
    "        for idx, column in enumerate(data_no_selection.columns.names[1:]):\n",
    "            object_properties[column] = d[idx+1]\n",
    "        \n",
    "        spacefluff_data.append(object_properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the list of objects to a DataFrame (and inspect the head to see if it worked properly)\n",
    "df_spacefluff_data = pd.DataFrame(spacefluff_data)\n",
    "\n",
    "#df_spacefluff_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the DataFrame to csv for later use:\n",
    "df_spacefluff_data.to_csv('./sf_spacefluff_object_data.csv', sep=\",\", index=False)\n",
    "\n",
    "# load and inspect created .csv to see if it saved correctly:\n",
    "df_spacefluff_data_read = pd.read_csv('./sf_spacefluff_object_data.csv', comment=\"#\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Compare properties\n",
    "\n",
    "Compare object properties between the selective and non-selective catalogues, to see if they match or if a different (more resource-intensive) method was used to extract objects' properties in the selective catalogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_object_property_match(index_sel, index_nosel):\n",
    "    '''\n",
    "    @param {int} index_sel: index of the object by this name in selected_data\n",
    "    @param {int} index_nosel: index of the object by this name in spacefluff_data\n",
    "    \n",
    "    '''\n",
    "    candidate_sel = selected_data[index_sel]        # properties of candidate according to `FDSDWARF_LSB.fits`\n",
    "    candidate_nosel = spacefluff_data[index_nosel]  # properties of candidate according to `LSBS_no_par_sel.fits`\n",
    "\n",
    "    columns_match = []\n",
    "    \n",
    "    if candidate_sel['name'] == candidate_nosel['name']:  \n",
    "        col_sel = set(candidate_sel.keys())      # get properties of objects offered by FDSDWARF_LSB.fits\n",
    "        col_nosel = set(candidate_nosel.keys())  # ^, but for LSBS_no_par_sel.fits\n",
    "\n",
    "        col_intersection = col_sel.intersection(col_nosel)  # get the properties present in both the .fits files, \n",
    "                                                            #  so we can compare them in a loop\n",
    "        for column in col_intersection:\n",
    "            match = candidate_sel[column] == candidate_nosel[column]\n",
    "            columns_match.append(match)\n",
    "\n",
    "        set_match = set(columns_match)\n",
    "        return set_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{True}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "# check if properties of UDGcand_3 match (I picked the indices by inspection)\n",
    "check_object_property_match(0, 2)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all properties that exist in both .fits files match for UDGcand_3. I manually also checked the other properties, and some don't have the same naming (PA vs. pos_angle), but for this candidate, they also match.\n",
    "\n",
    "Now, since we have most of the code anyway, let's check for all other objects that exist in SpaceFluff (note: in the creation of `spacefluff_data` I only selected objects in SpaceFluff, not all `UDGcand` objects. We could also check for all `UDGcand` objects, but I won't be doing that here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_sel = [d['target'] for d in data_selective]      # extract target names\n",
    "objects_nosel = [d['target'] for d in data_no_selection] # ^\n",
    "\n",
    "objects_intersection = set(objects_sel).intersection(set(objects_nosel))  # get the intersection of target names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_index_lookup = {}\n",
    "\n",
    "for object_name in objects_intersection:  # create object like {'UDGcand_1': { 'sel': None, 'nosel': None }}\n",
    "    object_index_lookup[object_name] = {  #  so we only have to loop each *_data list once\n",
    "        'sel': None,\n",
    "        'nosel': None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through each list (selected_data and spacefluff_data), and assign the object's index in the list to the lookup\n",
    "\n",
    "for index, obj in enumerate(selected_data):\n",
    "    if obj['name'] in objects_intersection:\n",
    "        object_index_lookup[obj['name']]['sel'] = index\n",
    "        \n",
    "for index, obj in enumerate(spacefluff_data):\n",
    "    if obj['name'] in objects_intersection:\n",
    "        object_index_lookup[obj['name']]['nosel'] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "# loop through the lookup and compare each object's properties. if any don't match, the loop'll print the object's name\n",
    "#  and we can manually investigate what's up\n",
    "\n",
    "all_match = 0\n",
    "not_in_spacefluff = 0\n",
    "\n",
    "for (name, indices) in object_index_lookup.items():\n",
    "    if type(indices['sel']) == int and type(indices['nosel']) == int:\n",
    "        set_match = check_object_property_match(indices['sel'], indices['nosel'])\n",
    "        \n",
    "        if set_match == set([True]):\n",
    "            all_match += 1\n",
    "        else:\n",
    "            print(\"Properties don't match, investigate!\", name, indices) \n",
    "    \n",
    "    else:\n",
    "        # object doesn't exist in SpaceFluff, which is not a problem\n",
    "        not_in_spacefluff += 1\n",
    "        continue\n",
    "    \n",
    "len(objects_intersection) == all_match + not_in_spacefluff"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python390jvsc74a57bd0bf9f9117a81b9c9429557cda2b87be7ef3b1b0b1cf7cef0eda783a94c339c64a",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}